{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec6821-5ed3-4645-ac72-04f16b8188b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc91092-21d9-4da4-883b-9e1ee8e2fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummarizer:\n",
    "    def __init__(self):\n",
    "        # Initialize spaCy model\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"Error: Please install the spaCy model by running:\")\n",
    "            print(\"python -m spacy download en_core_web_sm\")\n",
    "            raise\n",
    "    \n",
    "    def summarize(self, text, num_sentence=5):\n",
    "        \"\"\"\n",
    "        Generate a summary of the given text using TextRank algorithm\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to summarize\n",
    "            percent (float): Percentage of original text to include in summary (0.1 to 0.5)\n",
    "            \n",
    "        Returns:\n",
    "            str: The generated summary\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            return \"No text provided for summarization.\"\n",
    "        \n",
    "        return self.textrank_summary(text, num_sentence=5)\n",
    "    \n",
    "    def textrank_summary(self, text, num_sentence=5):\n",
    "        \"\"\"Generate text summary using TextRank algorithm\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        sentences = list(doc.sents)\n",
    "        \n",
    "        if len(sentences) <= 1:\n",
    "            return text\n",
    "        \n",
    "        # Create sentence vectors using spaCy's word vectors\n",
    "        sentence_vectors = []\n",
    "        for sent in sentences:\n",
    "            # Skip sentences with no words with vectors\n",
    "            if not any(token.has_vector for token in sent):\n",
    "                sent_vec = np.zeros((len(sent), 96))  # Default embedding dimension\n",
    "            else:\n",
    "                words_with_vectors = [token.vector for token in sent if token.has_vector]\n",
    "                if not words_with_vectors:\n",
    "                    sent_vec = np.zeros(96)  # Default dimension\n",
    "                else:\n",
    "                    sent_vec = np.mean(words_with_vectors, axis=0)\n",
    "            sentence_vectors.append(sent_vec)\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "        \n",
    "        # Fill the similarity matrix\n",
    "        for i in range(len(sentences)):\n",
    "            for j in range(len(sentences)):\n",
    "                if i != j:\n",
    "                    # Make sure we don't divide by zero\n",
    "                    if np.linalg.norm(sentence_vectors[i]) * np.linalg.norm(sentence_vectors[j]) == 0:\n",
    "                        sim_mat[i][j] = 0\n",
    "                    else:\n",
    "                        sim_mat[i][j] = self._cosine_similarity(sentence_vectors[i], sentence_vectors[j])\n",
    "        \n",
    "        # Create networkx graph and add edges with weights\n",
    "        nx_graph = nx.from_numpy_array(sim_mat)\n",
    "        \n",
    "        # Apply PageRank algorithm\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "        \n",
    "        # Sort sentences by score and select top sentences\n",
    "        ranked_sentences = sorted(((scores[i], i, s) for i, s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "        \n",
    "        # Get top N sentences and sort them by original position\n",
    "        top_sentences = sorted(ranked_sentences[:num_sentence], key=lambda x: x[1])\n",
    "        \n",
    "        # Combine sentences into summary\n",
    "        summary = \" \".join([s.text for _, _, s in top_sentences])\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "        # Handle zero vectors\n",
    "        if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "            return 0\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Sample text for demonstration\n",
    "#     sample_text = \"\"\"\n",
    "#     Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans. \n",
    "#     AI research has been defined as the field of study of intelligent agents, which refers to any system that perceives its environment and takes actions that maximize its chance of achieving its goals.\n",
    "#     The term \"artificial intelligence\" had previously been used to describe machines that mimic and display \"human\" cognitive skills that are associated with the human mind, such as \"learning\" and \"problem-solving\". \n",
    "#     This definition has since been rejected by major AI researchers who now describe AI in terms of rationality and acting rationally, which does not limit how intelligence can be articulated.\n",
    "#     AI applications include advanced web search engines, recommendation systems, understanding human speech, self-driving cars, automated decision-making and competing at the highest level in strategic game systems.\n",
    "#     As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. \n",
    "#     For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Create a summarizer\n",
    "#     summarizer = TextSummarizer()\n",
    "    \n",
    "#     # Generate summary at 30% length\n",
    "#     summary = summarizer.summarize(sample_text, 0.5)\n",
    "    \n",
    "#     # Print results\n",
    "#     print(\"Original Text Length:\", len(sample_text.split()), \"words\")\n",
    "#     print(\"Summary Length:\", len(summary.split()), \"words\")\n",
    "#     print(\"\\n--- SUMMARY ---\\n\")\n",
    "#     print(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f26a8-b1bf-421f-adeb-ea57b0d2e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file and return as a single string.\"\"\"\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text_content = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text.strip():\n",
    "            text_content.append(text.strip())\n",
    "    return \" \".join(text_content)\n",
    "\n",
    "def extract_text_from_docx(docx_file):\n",
    "    \"\"\"Extract text from a Word document and return as a single string.\"\"\"\n",
    "    doc = Document(docx_file)\n",
    "    text_content = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text.strip():\n",
    "            text_content.append(paragraph.text.strip())\n",
    "    return \" \".join(text_content)\n",
    "\n",
    "def extract_text(file):\n",
    "    \"\"\"Extract text from either PDF or Word document.\"\"\"\n",
    "    file_type = file.name.split('.')[-1].lower()\n",
    "    if file_type == 'pdf':\n",
    "        return extract_text_from_pdf(file)\n",
    "    elif file_type in ['docx', 'doc']:\n",
    "        return extract_text_from_docx(file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa094c8a-7971-4595-8756-e639d15e4f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dff5bb-b6cf-4a94-97d1-fb01229a2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File upload widget\n",
    "upload = widgets.FileUpload(accept='.pdf, .docx', multiple=False)\n",
    "process_button = widgets.Button(description=\"Process Request\")\n",
    "text_output = widgets.Output()\n",
    "\n",
    "\n",
    "# Process file and summarize\n",
    "def process_file(change):\n",
    "    summarizer = TextSummarizer()\n",
    "    \n",
    "    text_output.clear_output()\n",
    "    uploaded_file = list(upload.value.values())[0][\"content\"]\n",
    "    file_name = list(upload.value.keys())[0]\n",
    "\n",
    "    content = extract_text(uploaded_file)\n",
    "        \n",
    "    if not content.strip():\n",
    "        with text_output:\n",
    "            print(\"No extractable text found in the document.\")\n",
    "        return\n",
    "    \n",
    "    summary = summarizer.summarize(content, 5)\n",
    "    \n",
    "    with text_output:\n",
    "        clear_output()\n",
    "        print(\"Summary:\")\n",
    "        print(summary)\n",
    "\n",
    "process_button.on_click(process_file)\n",
    "\n",
    "display(upload, process_button, text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc7f82-e0c0-4d4d-8558-cb8a4e36a559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3dfd7a-6e44-4775-b829-bcc24e5ffe72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
